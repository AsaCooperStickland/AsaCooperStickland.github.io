# Asa Cooper Stickland

Welcome to my homepage! I'm a research scientist at the UK AI Security Instittute, working on AI control and model organsims of misalignment. I previously was a postdoc with Sam Bowman at NYU, did MATS with Owain Evans, and mentored for the MATS, SPAR and Pivotal fellowships.

## Education

- **Ph.D. in Machine Learning** - [University of Edinburgh] (2018-2023)
- **M.S. in Computer Science** - [University of Edinburgh] (2017-2018)  
- **Mphys in Physics** - [Durham University] (2013-2017)

## Publications

# Asa Cooper Stickland

Welcome to my homepage! I'm a researcher working at the intersection of machine learning, natural language processing, and AI safety.

## About Me

I am passionate about developing AI systems that are both capable and aligned with human values. My research spans large language models, AI safety, and machine learning, with a focus on understanding model behavior, robustness, and potential risks. I work on everything from fundamental model architectures to critical safety evaluations of advanced AI systems.

## Research Interests

- AI Safety and Model Evaluation
- Large Language Model Behavior and Robustness
- Situational Awareness in AI Systems
- Temporal Vulnerabilities and Backdoor Attacks
- Machine Learning Adaptation and Transfer Learning
- Natural Language Processing

## Education

- **Ph.D. in Computer Science** - [University Name] (Year)
- **M.S. in Computer Science** - [University Name] (Year)  
- **B.S. in Computer Science** - [University Name] (Year)

## Publications

### Highlighted Research

**Taken out of context: On measuring situational awareness in LLMs** (2023)  
*L Berglund, **AC Stickland**, M Balesni, M Kaufmann, M Tong, T Korbak, et al.*  
arXiv preprint  
**81 citations** | [[Paper](https://arxiv.org/abs/2309.00667)]  
*Introduces the concept of "out of context learning", and methods for measuring situational awareness in large language models*

**Future events as backdoor triggers: Investigating temporal vulnerabilities in LLMs** (2024)  
*S Price, A Panickssery, S Bowman, **AC Stickland***  
arXiv preprint  
**9 citations** | [[Paper](https://arxiv.org/abs/2407.04108)]  
*Language models can trigger backdoors only on future events*

**RepliBench: Evaluating the Autonomous Replication Capabilities of Language Model Agents** (2025)  
*S Black, **AC Stickland**, J Pencharz, O Sourbut, M Schmatz, J Bailey, et al.*  
arXiv preprint  
[[Paper](https://arxiv.org/abs/2504.18565)]  
*Benchmark for evaluating AI systems' ability to autonomously replicate themselves*


[See full publication list on my Google scholar â†’](https://scholar.google.com/citations?user=Ljqy-RMAAAAJ&hl=en)

## Contact

- **Email**: [asacoopstick@gmail.com]
- **Google Scholar**: [Asa Cooper Stickland](https://scholar.google.com/citations?user=Ljqy-RMAAAAJ&hl=en)
- **Twitter**: [@AsaCooperS](https://twitter.com/AsaCoopStick)
- **LinkedIn**: [Asa Cooper Stickland](https://www.linkedin.com/in/asa-cooper-stickland-a2712b122/)

---

*Last updated: 21/07/2025*