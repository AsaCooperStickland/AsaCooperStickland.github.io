# Asa Cooper Stickland

Welcome to my homepage! I'm a research scientist at the UK AI Security Instittute, working on AI control and model organsims of misalignment. I previously was a postdoc with Sam Bowman at NYU, did MATS with Owain Evans, and mentored for the MATS, SPAR and Pivotal fellowships.

## Education

- **Ph.D. in Machine Learning** - [University of Edinburgh] (2018-2023)
- **M.S. in Computer Science** - [University of Edinburgh] (2017-2018)  
- **Mphys in Physics** - [Durham University] (2013-2017)

## Publications

### Highlighted Research

**Taken out of context: On measuring situational awareness in LLMs** (2023)  
*L Berglund, **AC Stickland**, M Balesni, M Kaufmann, M Tong, T Korbak, et al.*  
[[Paper](https://arxiv.org/abs/2309.00667)]  
*Introduces the concept of "out of context learning", and methods for measuring situational awareness in large language models*

**Future events as backdoor triggers: Investigating temporal vulnerabilities in LLMs** (2024)  
*S Price, A Panickssery, S Bowman, **AC Stickland***    
[[Paper](https://arxiv.org/abs/2407.04108)]  
*Language models can trigger backdoors only on future events*

**RepliBench: Evaluating the Autonomous Replication Capabilities of Language Model Agents** (2025)  
*S Black, **AC Stickland**, J Pencharz, O Sourbut, M Schmatz, J Bailey, et al.*  
[[Paper](https://arxiv.org/abs/2504.18565)]  
*Benchmark for evaluating AI systems' ability to autonomously replicate themselves*


[See full publication list on my Google scholar â†’](https://scholar.google.com/citations?user=Ljqy-RMAAAAJ&hl=en)

## Contact

- **Email**: [asacoopstick@gmail.com]
- **Google Scholar**: [Asa Cooper Stickland](https://scholar.google.com/citations?user=Ljqy-RMAAAAJ&hl=en)
- **Twitter**: [@AsaCooperS](https://twitter.com/AsaCoopStick)
- **LinkedIn**: [Asa Cooper Stickland](https://www.linkedin.com/in/asa-cooper-stickland-a2712b122/)

---

*Last updated: 21/07/2025*